{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import networkx as nx\n",
    "import os\n",
    "import copy\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble,metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "\n",
    "def compute_metrices_detector(y_true, y_pred):\n",
    "    accuracy  = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    precision = precision_score(y_true=y_true, y_pred=y_pred)\n",
    "    recall    = recall_score(y_true=y_true, y_pred=y_pred)\n",
    "    f1        = f1_score(y_true=y_true, y_pred=y_pred)\n",
    "    return {'accuracy': accuracy, \n",
    "            'precision': precision, \n",
    "            'recall': recall, \n",
    "            'f1': f1}\n",
    "    \n",
    "def compute_metrices_classifier(y_true, y_pred):\n",
    "    accuracy  = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    precision = precision_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "    recall    = recall_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "    f1        = f1_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "    return {'accuracy':  accuracy, \n",
    "            'precision': precision, \n",
    "            'recall':    recall, \n",
    "            'f1':        f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_df = pd.read_csv('./feature/Ben_feature_sym.csv',header=None)\n",
    "mal_df = pd.read_csv('./feature/Mal_feature_sym.csv',header=None)\n",
    "\n",
    "mal_df.iloc[:,1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_df = ben_df.dropna() \n",
    "mal_df = mal_df.dropna()\n",
    "mask = mal_df.iloc[:, 1] == 9\n",
    "mal_df = mal_df[~mask]\n",
    "\n",
    "mal_df.iloc[:,1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_df.to_numpy()\n",
    "mal_df.to_numpy()\n",
    "data = np.concatenate((ben_df,mal_df),axis=0)\n",
    "X = data[:,2:]\n",
    "y = data[:, 1]\n",
    "\n",
    "# y = np.where(y==0,0,1)\n",
    "\n",
    "#對label 做one hot encoding\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(y)\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "# onehotencoder = OneHotEncoder()\n",
    "# data_str_ohe =onehotencoder.fit_transform(label).toarray()\n",
    "# label = pd.DataFrame(data_str_ohe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF\n",
    "forest = ensemble.RandomForestClassifier(n_estimators = 110)\n",
    "forest_fit = forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = forest.predict(X_train)    \n",
    "print('RF :',accuracy_score(Y_train,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrices_classifier(Y_train,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(forest,\"RF_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN \n",
    "knn = KNeighborsClassifier(weights='distance',n_neighbors=5)\n",
    "knn_fit = knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = knn.predict(X_test)\n",
    "print('KNN',accuracy_score(Y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrices_classifier(Y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(knn,\"KNN_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = svm_model.predict(X_train)\n",
    "print('SVM',accuracy_score(Y_train,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrices_classifier(Y_train,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(svm_model,\"SVM_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lin1 = Linear(num_features, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        ## ignore softmax activation here, since we can obtain\n",
    "        ## higher accuracy in our case\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TorchTrainer:\n",
    "    def __init__(self, model, optimizer=None, criterion=None, device=None):\n",
    "        self.model     = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu') if device is None else device\n",
    "                \n",
    "        self.arguments = locals()\n",
    "        self.arguments['device'] = self.device\n",
    "        \n",
    "        self.output_dim = list(self.model.modules())[-1].out_features\n",
    "    \n",
    "    def train(self, train_loader, valid_loader, epochs=20, save_path='model_saved/mlp.pt', verbose=True):\n",
    "        self.arguments['epochs'] = epochs\n",
    "        self.arguments['save_path'] = save_path\n",
    "        \n",
    "        train_acc  = np.zeros(epochs)\n",
    "        train_loss = np.zeros(epochs)\n",
    "        val_acc    = np.zeros(epochs)\n",
    "        val_loss   = np.zeros(epochs)\n",
    "        train_time = np.zeros(epochs)\n",
    "        \n",
    "        best_val_acc = 0\n",
    "        for epoch in range(epochs):\n",
    "            if verbose:\n",
    "                epoch_start = f'Epoch ({epoch + 1}/{epochs})'\n",
    "                print(epoch_start, end=' ')\n",
    "\n",
    "            train_time[epoch] = self.train_epoch(train_loader)\n",
    "\n",
    "            # evaluate the training accuracy and validation accuracy after each epoch\n",
    "            train_acc[epoch], train_loss[epoch] = self.test(train_loader)\n",
    "            val_acc[epoch], val_loss[epoch] = self.test(valid_loader)\n",
    "\n",
    "            if val_acc[epoch] > best_val_acc:\n",
    "                # save the best model according to validation accuracy\n",
    "                best_val_acc = val_acc[epoch]\n",
    "                torch.save(self.model, save_path)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'Train Acc: {train_acc[epoch]:.4f}, Train Loss: {train_loss[epoch]:>7.6f}', end=', ')\n",
    "                print(f'Val Acc: {val_acc[epoch]:.4f}, Val Loss: {val_loss[epoch]:>7.6f}', end=' -- ')\n",
    "                print(f'Training Time: {train_time[epoch]:.2f}s')\n",
    "        \n",
    "        self.history = {'train_acc':  train_acc, \n",
    "                        'train_loss': train_loss, \n",
    "                        'val_acc':    val_acc, \n",
    "                        'val_loss':   val_loss, \n",
    "                        'time':       train_time}\n",
    "\n",
    "    def train_epoch(self, train_loader):\n",
    "        start = time()\n",
    "        \n",
    "        self.model.train()\n",
    "        for data, label in train_loader:        # Iterate in batches over the training dataset.\n",
    "            data.to(self.device)                # Train the data if gpu is available\n",
    "            out = self.model(data)              # Perform a single forward pass.\n",
    "            y = F.one_hot(label, num_classes=self.output_dim).to(torch.float)\n",
    "            loss = self.criterion(out, y)       # Compute the loss.\n",
    "            \n",
    "            loss.backward()                     # Derive gradients.\n",
    "            self.optimizer.step()               # Update parameters based on gradients.\n",
    "            self.optimizer.zero_grad()          # Clear gradients.\n",
    "        \n",
    "        end = time()\n",
    "        return end - start\n",
    "\n",
    "    def test(self, loader):\n",
    "        self.model.eval()\n",
    "\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        for data, label in loader:                      # Iterate in batches over the training/test dataset.\n",
    "            data.to(self.device)                        # Train the data if gpu is available\n",
    "            out = self.model(data)                      # Predict the outcome by trained model\n",
    "            y = F.one_hot(label, num_classes=self.output_dim).to(torch.float)\n",
    "            loss += self.criterion(out, y).item()       # Get the loss accumulated of each data sample\n",
    "            \n",
    "            pred = out.argmax(dim=1)                    # Use the class with highest probability.\n",
    "            correct += int((pred == label).sum())       # Check against ground-truth labels.\n",
    "\n",
    "        acc = correct / len(loader.dataset)             # Get the accuracy\n",
    "        avg_loss = loss / len(loader.dataset)           # Get the average loss\n",
    "        return (acc, avg_loss)                          # Return the accuracy and average loss\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.model = torch.load(path)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, loader):\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                data.to(self.device)\n",
    "                pred = self.model(data).cpu().detach()\n",
    "                preds.append(pred)\n",
    "        preds = torch.vstack(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MalwareDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, n_or_frac, column='family', shuffle=True, allow_lower_n=False):\n",
    "    if type(n_or_frac) is int:\n",
    "        if allow_lower_n:\n",
    "            train_df = df.groupby(column).apply(lambda x: x.sample(n=n_or_frac if x.shape[0]>=n_or_frac else x.shape[0])).droplevel(level=0)\n",
    "        else:\n",
    "            train_df = df.groupby(column).sample(n=n_or_frac)\n",
    "                \n",
    "    else:\n",
    "        train_df = df.groupby(column).sample(frac=n_or_frac)\n",
    "    valid_df = df[~df.index.isin(train_df.index)]\n",
    "    \n",
    "    if shuffle:\n",
    "        train_df = train_df.sample(frac=1)\n",
    "        valid_df = valid_df.sample(frac=1)\n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ben_df, mal_df])\n",
    "# label_map = {label: i for i, label in enumerate(df.iloc[:, 1].value_counts().index)}\n",
    "label_map = {i: i for i in range(9)}\n",
    "df = df.assign(family=df.iloc[:, 1].apply(lambda x: label_map[x]))\n",
    "df = df.assign(malicious=(df.family!=0).astype(np.int64))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifier\n",
    "\n",
    "# train_df, valid_df = split_df(df, n_or_frac=0.8 ,column='family', shuffle=True, allow_lower_n=True) # family\n",
    "# train_df, test_df  = split_df(train_df, n_or_frac=10000, column='family', shuffle=True, allow_lower_n=True) # family\n",
    "# print('Family: ')\n",
    "# print('Train: ')\n",
    "# print(train_df.family.value_counts())\n",
    "# print()\n",
    "# print('Valid: ')\n",
    "# print(valid_df.family.value_counts())\n",
    "\n",
    "# X_train = train_df.iloc[:, 2:9].to_numpy()\n",
    "# Y_train = train_df.family.to_numpy()\n",
    "# X_test  = valid_df.iloc[:, 2:9].to_numpy()\n",
    "# Y_test  = valid_df.family.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detector\n",
    "\n",
    "train_df, valid_df = split_df(df, n_or_frac=0.8, column='malicious', shuffle=True, allow_lower_n=True)  # detector\n",
    "print('Malicious: ')\n",
    "print('Train: ')\n",
    "print(train_df.malicious.value_counts())\n",
    "print()\n",
    "print('Valid: ')\n",
    "print(valid_df.malicious.value_counts())\n",
    "\n",
    "X_train = train_df.iloc[:, 2:9].to_numpy()\n",
    "Y_train = train_df.malicious.to_numpy()\n",
    "X_test  = valid_df.iloc[:, 2:9].to_numpy()\n",
    "Y_test  = valid_df.malicious.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# device     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device     = torch.device('cpu')\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.astype(np.float32))\n",
    "X_test_tensor  = torch.tensor(X_test.astype(np.float32))\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.long)   # detector\n",
    "Y_test_tensor  = torch.tensor(Y_test, dtype=torch.long)    # detector\n",
    "\n",
    "train_ds = MalwareDataset(X_train_tensor, Y_train_tensor)\n",
    "valid_ds = MalwareDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, num_workers=0, drop_last=True, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=128, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(num_features=X_train_tensor.size(1), hidden_channels=64, num_classes=Y_train_tensor.unique().size(0)).to(device)\n",
    "# model = MLPCls(num_features=X_train_tensor.size(1), hidden_channels=64, num_classes=Y_train_tensor.unique().size(0)).to(device)\n",
    "\n",
    "# define device of model before sending to the optimizer model.parameters() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # detector lr = 0.0008\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(f'Device: {device}\\n')\n",
    "print(f'Model: \\n{model}\\n')\n",
    "print(f'Optimizer: \\n{optimizer}\\n')\n",
    "print(f'Criterion: {criterion}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = TorchTrainer(model, optimizer=optimizer, criterion=criterion, device=device)\n",
    "\n",
    "madel_path = './mlp_md.pt'\n",
    "trainer.train(train_loader=train_loader, \n",
    "              valid_loader=valid_loader, \n",
    "              epochs=30, \n",
    "              save_path=madel_path, \n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = np.ones(7)\n",
    "fake2 = np.zeros(7)\n",
    "np.vstack([fake,fake2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_trainer = TorchTrainer(model)\n",
    "predict_trainer.load('./detection_model/mlp_md.pt')\n",
    "\n",
    "train_data_loader = DataLoader(X_train_tensor, batch_size=batch_size, num_workers=0, drop_last=False, shuffle=False)\n",
    "print(train_data_loader.dataset.shape)\n",
    "valid_data_loader = DataLoader(X_test_tensor, batch_size=batch_size, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "train_pred = predict_trainer.predict(train_data_loader).argmax(dim=1)\n",
    "valid_pred = predict_trainer.predict(valid_data_loader).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrices(y_true, y_pred, average='binary'):\n",
    "    accuracy  = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    precision = precision_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "    recall    = recall_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "    f1        = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "    return {'accuracy':  accuracy, \n",
    "            'precision': precision, \n",
    "            'recall':    recall, \n",
    "            'f1':        f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train metrics')\n",
    "compute_metrices(Y_train_tensor, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Valid metrics')\n",
    "compute_metrices(Y_test_tensor, valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
